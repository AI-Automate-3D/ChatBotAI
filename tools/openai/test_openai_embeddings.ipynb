{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAI Embeddings — Test Notebook\n",
    "\n",
    "Test the OpenAI embedding & ingestion pipeline: config loading, document parsing,\n",
    "embedding generation, and Pinecone upsert.\n",
    "\n",
    "Section 1 runs without API keys. Sections 2+ require OpenAI/Pinecone keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path.cwd().parent.parent if Path.cwd().name == \"openai\" else Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration & Model Info\n",
    "\n",
    "Test loading config and checking available models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.openai.OpenAI_embeddings import MODELS, load_config\n",
    "\n",
    "# Available embedding models\n",
    "print(\"Available models:\")\n",
    "for key, info in MODELS.items():\n",
    "    print(f\"  {key}: {info['name']} ({info['dimensions']} dims) — {info['description']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load config (if available)\n",
    "config_path = str(PROJECT_ROOT / \"_config files\" / \"config.json\")\n",
    "\n",
    "try:\n",
    "    cfg, raw_config = load_config(config_path)\n",
    "    openai_cfg = raw_config.get(\"openai\", {})\n",
    "    print(f\"Pinecone index: {cfg.index_name}\")\n",
    "    print(f\"Namespace:      {cfg.namespace}\")\n",
    "    print(f\"Embedding model: {openai_cfg.get('embedding_model', 'not set')}\")\n",
    "    print(f\"OpenAI key:     {'set' if openai_cfg.get('api_key') else 'missing'}\")\n",
    "except SystemExit as e:\n",
    "    print(f\"Config not available: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Parse Knowledge Base Documents\n",
    "\n",
    "Test parsing .docx files from the test data folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.pinecone.parser import parse_docx, parse_kb_text\n",
    "\n",
    "# Check for test data files\n",
    "test_data_dir = PROJECT_ROOT / \"__test_data\"\n",
    "if test_data_dir.exists():\n",
    "    docx_files = sorted(test_data_dir.rglob(\"*.docx\"))\n",
    "    print(f\"Found {len(docx_files)} .docx file(s):\")\n",
    "    for f in docx_files:\n",
    "        print(f\"  {f.relative_to(PROJECT_ROOT)}\")\n",
    "else:\n",
    "    print(f\"Test data directory not found: {test_data_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse a test .docx file (requires python-docx)\n",
    "if test_data_dir.exists():\n",
    "    docx_files = sorted(test_data_dir.rglob(\"*.docx\"))\n",
    "    if docx_files:\n",
    "        # Use the knowledge base file (not the system message)\n",
    "        kb_file = [f for f in docx_files if \"knowledgeBase\" in f.name]\n",
    "        target = kb_file[0] if kb_file else docx_files[0]\n",
    "        \n",
    "        try:\n",
    "            chunks = parse_docx(str(target))\n",
    "            print(f\"Parsed {len(chunks)} chunk(s) from {target.name}:\\n\")\n",
    "            for chunk in chunks[:3]:  # Show first 3\n",
    "                print(f\"  ID:    {chunk['id']}\")\n",
    "                print(f\"  Type:  {chunk.get('type', '')}\")\n",
    "                print(f\"  Title: {chunk.get('title', '')}\")\n",
    "                print(f\"  Text:  {chunk['text'][:100]}...\")\n",
    "                print()\n",
    "            if len(chunks) > 3:\n",
    "                print(f\"  ... and {len(chunks) - 3} more chunk(s)\")\n",
    "        except ImportError:\n",
    "            print(\"Install python-docx: pip install python-docx\")\n",
    "    else:\n",
    "        print(\"No .docx files found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse inline KB text (no file needed)\n",
    "sample_kb = \"\"\"\n",
    "KB_ID: demo-001\n",
    "TYPE: product\n",
    "TITLE: Midnight Velvet Dress\n",
    "TEXT:\n",
    "A stunning floor-length velvet dress in deep midnight blue.\n",
    "Available in sizes XS-XL. Price: $289.99.\n",
    "--- KB_CHUNK_END ---\n",
    "\n",
    "KB_ID: demo-002\n",
    "TYPE: policy\n",
    "TITLE: Gift Wrapping\n",
    "TEXT:\n",
    "We offer complimentary gift wrapping on all orders.\n",
    "Select the gift wrap option at checkout.\n",
    "--- KB_CHUNK_END ---\n",
    "\"\"\"\n",
    "\n",
    "demo_chunks = parse_kb_text(sample_kb)\n",
    "print(f\"Parsed {len(demo_chunks)} demo chunk(s):\")\n",
    "for c in demo_chunks:\n",
    "    print(f\"  [{c['id']}] {c['title']}: {c['text'][:60]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Embeddings (requires OpenAI API key)\n",
    "\n",
    "Create embedding vectors from the parsed chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.openai.OpenAI_embeddings import make_embed_fn\n",
    "\n",
    "# Set your OpenAI API key\n",
    "# OPENAI_API_KEY = \"sk-...\"\n",
    "\n",
    "# embed_fn = make_embed_fn(OPENAI_API_KEY, \"text-embedding-3-small\")\n",
    "# vector = embed_fn(\"What is the return policy?\")\n",
    "# print(f\"Embedding dimensions: {len(vector)}\")\n",
    "# print(f\"First 5 values: {vector[:5]}\")\n",
    "\n",
    "print(\"Uncomment and set OPENAI_API_KEY to test embeddings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Pipeline: Parse, Embed, Upsert (requires both API keys)\n",
    "\n",
    "Run the complete ingestion pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.pinecone.vector_store import VectorStore\n",
    "from tools.pinecone.config import PineconeConfig\n",
    "\n",
    "# Uncomment after setting up config.json:\n",
    "\n",
    "# cfg, raw_config = load_config(config_path)\n",
    "# openai_key = raw_config[\"openai\"][\"api_key\"]\n",
    "# embed_fn = make_embed_fn(openai_key, \"text-embedding-3-small\")\n",
    "\n",
    "# store = VectorStore(cfg, embed_fn=embed_fn)\n",
    "\n",
    "# # Upsert demo chunks\n",
    "# store.upsert_texts(demo_chunks)\n",
    "# print(f\"Upserted {len(demo_chunks)} chunks\")\n",
    "\n",
    "# # Query\n",
    "# results = store.query_text(\"Do you gift wrap?\", top_k=2)\n",
    "# for r in results:\n",
    "#     print(f\"  Score: {r['score']:.4f} — {r['metadata'].get('title', '')}\")\n",
    "#     print(f\"  {r['metadata'].get('text', '')[:100]}\")\n",
    "\n",
    "# # Stats\n",
    "# print(f\"\\nIndex stats: {store.stats()}\")\n",
    "\n",
    "print(\"Uncomment after setting up config.json with valid API keys.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
