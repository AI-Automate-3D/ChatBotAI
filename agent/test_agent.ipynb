{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Module — Test Notebook\n",
    "\n",
    "Test the RAG agent pipeline: prompt loading, memory management, chat completion, and the full `run()` function.\n",
    "\n",
    "Each section can be run independently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure the project root is on the path\n",
    "PROJECT_ROOT = Path.cwd().parent if Path.cwd().name == \"agent\" else Path.cwd()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "print(f\"Project root: {PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load System Prompt\n",
    "\n",
    "Test loading prompts from text, docx, or using a default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.prompt import load_prompt\n",
    "\n",
    "# Load from the default built-in prompt\n",
    "default_prompt = load_prompt(None)\n",
    "print(\"Default prompt:\")\n",
    "print(default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from a custom string fallback\n",
    "custom_prompt = load_prompt(None, default=\"You are a friendly shopping assistant for Jaded Rose.\")\n",
    "print(\"Custom prompt:\")\n",
    "print(custom_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from the system_prompt.txt file\n",
    "prompt_path = PROJECT_ROOT / \"agent\" / \"system_prompt.txt\"\n",
    "if prompt_path.exists():\n",
    "    file_prompt = load_prompt(prompt_path)\n",
    "    print(f\"Loaded from {prompt_path}:\")\n",
    "    print(file_prompt[:200], \"...\" if len(file_prompt) > 200 else \"\")\n",
    "else:\n",
    "    print(f\"File not found: {prompt_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Memory Management\n",
    "\n",
    "Test saving, loading, and clearing conversation memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.memory import load_memory, save_memory, clear_memory, append_exchange, get_pair_count\n",
    "import tempfile, os\n",
    "\n",
    "# Use a temp file so we don't overwrite real memory\n",
    "test_memory_path = os.path.join(tempfile.gettempdir(), \"test_memory.json\")\n",
    "\n",
    "# Start with empty memory\n",
    "history = load_memory(test_memory_path)\n",
    "print(f\"Initial history: {history}\")\n",
    "print(f\"Pair count: {get_pair_count(history)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some exchanges\n",
    "history = append_exchange(history, \"What is your return policy?\", \"You can return items within 30 days.\")\n",
    "history = append_exchange(history, \"Do you ship internationally?\", \"Yes, we ship to over 50 countries.\")\n",
    "\n",
    "print(f\"History has {get_pair_count(history)} exchange(s):\")\n",
    "for msg in history:\n",
    "    print(f\"  [{msg['role']}] {msg['content'][:60]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save and reload\n",
    "save_memory(test_memory_path, history, max_pairs=10)\n",
    "\n",
    "reloaded = load_memory(test_memory_path)\n",
    "print(f\"Reloaded {get_pair_count(reloaded)} exchange(s) from disk\")\n",
    "assert reloaded == history, \"Memory round-trip failed!\"\n",
    "print(\"Round-trip OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear memory\n",
    "clear_memory(test_memory_path)\n",
    "print(f\"After clear: {load_memory(test_memory_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chat Completion (build_messages)\n",
    "\n",
    "Test message construction without making API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.chat import build_messages\n",
    "\n",
    "# Example inputs\n",
    "system_prompt = \"You are a helpful shopping assistant.\"\n",
    "context = \"[1] Returns are accepted within 30 days.\\n\\n[2] Free shipping on orders over $50.\"\n",
    "history = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi there!\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Hello! How can I help you today?\"},\n",
    "]\n",
    "question = \"What is your return policy?\"\n",
    "\n",
    "messages = build_messages(system_prompt, context, history, question)\n",
    "\n",
    "print(f\"Total messages: {len(messages)}\\n\")\n",
    "for i, msg in enumerate(messages):\n",
    "    print(f\"[{i}] role={msg['role']}\")\n",
    "    print(f\"    {msg['content'][:100]}...\" if len(msg['content']) > 100 else f\"    {msg['content']}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without context — context message should be omitted\n",
    "messages_no_ctx = build_messages(system_prompt, \"\", [], \"Hello\")\n",
    "print(f\"Messages without context: {len(messages_no_ctx)}\")\n",
    "for msg in messages_no_ctx:\n",
    "    print(f\"  [{msg['role']}] {msg['content'][:80]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Full Agent Run (requires API keys)\n",
    "\n",
    "This cell calls the live OpenAI and Pinecone APIs.\n",
    "Make sure your `config.json` is set up before running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.agent import run\n",
    "\n",
    "# Direct function call — pass a question, get an answer\n",
    "question = \"What products do you sell?\"\n",
    "\n",
    "try:\n",
    "    answer = run(question)\n",
    "    print(f\"Q: {question}\")\n",
    "    print(f\"A: {answer}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Config not found (expected if no config.json): {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Follow-up question (uses memory from the previous call)\n",
    "followup = \"Can I get a discount on those?\"\n",
    "\n",
    "try:\n",
    "    answer2 = run(followup)\n",
    "    print(f\"Q: {followup}\")\n",
    "    print(f\"A: {answer2}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Config not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a custom system prompt override\n",
    "try:\n",
    "    answer3 = run(\n",
    "        \"Tell me a joke\",\n",
    "        system_prompt_override=\"You are a comedian. Always respond with a joke.\",\n",
    "    )\n",
    "    print(f\"A: {answer3}\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Config not found: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
